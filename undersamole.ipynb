{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":7613886,"sourceType":"datasetVersion","datasetId":4433918},{"sourceId":7672800,"sourceType":"datasetVersion","datasetId":4475539}],"dockerImageVersionId":30646,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport warnings\nfrom imblearn.over_sampling import SMOTE\nfrom imblearn.pipeline import make_pipeline\nfrom pylab import rcParams\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn import tree\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import precision_score, recall_score\nfrom sklearn.metrics import f1_score, roc_auc_score, roc_curve\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import confusion_matrix \nfrom time import perf_counter\nfrom time import process_time\nimport timeit","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# loading the dataset to a pandas DataFrame \n#df = pd.read_csv('/kaggle/input/credit-card-undersample/creditcard.csv')\ndf = pd.read_csv('/kaggle/input/creditcard2023/creditcard_2023.csv')\ndf","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\" \\nCount total NaN at each column in a DataFrame : \\n\\n\", \n      df.isnull().sum()) \n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"target = 'Class'\nX = df.loc[:, df.columns!=target]\nY = df.loc[:, df.columns==target]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train, X_test, Y_train, Y_test = train_test_split(X, Y, \n                                                    test_size=0.2, \n                                                    random_state=42)\n\n\nax = sns.countplot(x=target, data=df)\nprint(df[target].value_counts())\nY_train[target].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''sm = SMOTE(random_state=12, sampling_strategy=1.0)\nx_train_res, y_train_res = sm.fit_resample(X_train, Y_train)\nunique, count = np.unique(y_train_res, return_counts=True)\ny_train_smote_value_count = { k:v for (k,v) in zip(unique, count)}\ny_train_smote_value_count\nX=x_train_res\nY=y_train_res'''","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ax = sns.countplot(x=target, data=Y_train)\nprint(df[target].value_counts())\nY_train[target].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# SMOTETomek","metadata":{}},{"cell_type":"code","source":"'''from imblearn.combine import SMOTETomek\n\ns_tomek = SMOTETomek(random_state = 42)\nx_train_res, y_train_res = s_tomek.fit_resample(X_train,Y_train)\nunique, count = np.unique(y_train_res, return_counts=True)\ny_train_smote_value_count = { k:v for (k,v) in zip(unique, count)}\ny_train_smote_value_count'''","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train.shape\nprint(Y['Class'].value_counts())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def generate_model_report(y_actual, y_predicted):\n    print(\"Accuracy = \" , accuracy_score(y_actual, y_predicted))\n    print(\"Precision = \" ,precision_score(y_actual, y_predicted))\n    print(\"Recall = \" ,recall_score(y_actual, y_predicted))\n    print(\"F1 Score = \" ,f1_score(y_actual, y_predicted))\n    pass\n\n\ndef generate_auc_roc_curve(clf, X_test):\n    y_pred_proba = clf.predict_proba(X_test)[:, 1]\n    fpr, tpr, thresholds = roc_curve(Y_test,  y_pred_proba)\n    auc = roc_auc_score(Y_test, y_pred_proba)\n    plt.plot(fpr,tpr,label=\"AUC ROC Curve with Area Under the curve =\"+str(auc))\n    plt.legend(loc=4)\n    plt.show()\n    pass","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X.corr()\n\nimport seaborn as sns\n#Using Pearson Correlation\nplt.figure(figsize=(20,30))\ncor = X.corr()\nsns.heatmap(cor, annot=True, cmap=plt.cm.autumn)\nplt.show()\ndef correlation(dataset, threshold):#dataset is X_train , threshold is a value which is may be 80% ,90% ,70%.. \n    col_corr = set()  # Set of all the names of correlated columns\n    # using set() so no duplicate column contain here ...\n    corr_matrix = dataset.corr()\n    for i in range(len(corr_matrix.columns)):\n        for j in range(i):\n            if abs(corr_matrix.iloc[i, j]) > threshold: # we are interested in absolute coeff value\n                colname = corr_matrix.columns[i]  # getting the name of column\n                col_corr.add(colname)\n    return col_corr\n\ncorr_features = correlation(X, 0.95)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(set(corr_features))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"corr_features","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for col in corr_features:\n    for col1 in X.columns:\n        if col1==col:\n            #print(col)\n            del X_train[col]\n            del X_test[col]\nprint(X_train)\nprint(X_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#X_train=X","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nrf = RandomForestClassifier(n_jobs=4, \n                             random_state=2018,\n                             criterion='gini',\n                             n_estimators=100,\n                             verbose=False)\nrf.fit(X_train, Y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rf.feature_importances_","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#creating a table for checking the importance of different variables  \nfeat_imp=pd.DataFrame({\"Features\":X_train.columns,\"Importance\":rf.feature_importances_}).sort_values(by=\"Importance\",ascending=False)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"feat_imp","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## visualizing the importance of variables\nplt.figure(figsize=(12,6))\nsns.barplot(data=feat_imp,x=\"Features\",y=\"Importance\")\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#filtering out the variables having more than 1% impact on the model\nfeat_imp[feat_imp[\"Importance\"]>0.015][\"Features\"].unique()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## selecting the important variabels\nX_train=X_train[['id', 'V14', 'V12', 'V4', 'V11', 'V10', 'V17', 'V16', 'V18', 'V3']]\n\nX_test=X_test[['id', 'V14', 'V12', 'V4', 'V11', 'V10', 'V17', 'V16', 'V18', 'V3']]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import MinMaxScaler\nmin_max = MinMaxScaler()\nX_train = pd.DataFrame(min_max.fit_transform(X_train), columns=X_train.columns)\nX_train","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_test = pd.DataFrame(\n    min_max.transform(X_test),\n    columns = X_test.columns\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#X=X_train","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Correlation","metadata":{}},{"cell_type":"code","source":"'''X.corr()\n\nimport seaborn as sns\n#Using Pearson Correlation\nplt.figure(figsize=(12,20))\ncor = X.corr()\nsns.heatmap(cor, annot=True, cmap=plt.cm.autumn)\nplt.show()\ndef correlation(dataset, threshold):#dataset is X_train , threshold is a value which is may be 80% ,90% ,70%.. \n    col_corr = set()  # Set of all the names of correlated columns\n    # using set() so no duplicate column contain here ...\n    corr_matrix = dataset.corr()\n    for i in range(len(corr_matrix.columns)):\n        for j in range(i):\n            if abs(corr_matrix.iloc[i, j]) > threshold: # we are interested in absolute coeff value\n                colname = corr_matrix.columns[i]  # getting the name of column\n                col_corr.add(colname)\n    return col_corr\n\ncorr_features = correlation(X, 0.85)'''","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#len(set(corr_features))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#corr_features","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''for col in corr_features:\n    for col1 in X.columns:\n        if col1==col:\n            #print(col)\n            del X[col]\n            del X_test[col]\nprint(X)\nprint(X_test)'''","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Hyperparameter for Decision Tree","metadata":{}},{"cell_type":"code","source":"dt_hp = tree.DecisionTreeClassifier(random_state=43)\n\nparams = {'max_depth':[2,10,15],\n          'min_samples_leaf':[1,3,5],\n          'min_samples_split':[1,2,5,8],\n          'criterion':['gini','entropy']}\nGS = GridSearchCV(estimator=dt_hp,param_grid=params,cv=5,n_jobs=-1, verbose=True, scoring='accuracy')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#GS.fit(X_train, Y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#print('Best Parameters:',GS.best_params_,end='\\n\\n')\n#print('Best Score:',GS.best_score_)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn import tree\nclassify_ = tree.DecisionTreeClassifier(criterion= 'entropy', max_depth= 10, min_samples_leaf= 6, min_samples_split= 3)\nstart_time = timeit.default_timer()\nclassify_ = classify_.fit(X_train,Y_train)\n\nend_time = timeit.default_timer()\nelapsed_time = end_time - start_time\n\nprint(\"Elapsed time : \",elapsed_time)\n\n#Accuracy on training data\nx_train_prediction = classify_.predict(X_train)\ntraining_data_accuracy = accuracy_score(x_train_prediction , Y_train)\nprint('Accuracy on Training data DT: , ', training_data_accuracy)\n\n# accuracy on test data \nx_test_prediction = classify_.predict(X_test)\ntest_data_accuracy=accuracy_score(x_test_prediction,Y_test)\nprint('Accuracy score on Test data DT:' ,test_data_accuracy)\n\ngenerate_model_report(Y_test, x_test_prediction)\ncf_matrix=confusion_matrix(x_test_prediction,Y_test)\nprint(cf_matrix)\nsns.heatmap(cf_matrix, annot=True, cmap='Blues',fmt='g')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Hyperparameter for XGBoost","metadata":{}},{"cell_type":"code","source":"from hyperopt import STATUS_OK, Trials, fmin, hp, tpe\nfrom xgboost import XGBClassifier\nmodel = XGBClassifier()\nparams ={'max_depth':[1,10,20,50],\n        'gamma':[0],\n        'reg_alpha' :[ 1],\n        'reg_lambda' :[1],\n        'colsample_bytree' :  [0,1],\n        'min_child_weight' : [1],\n        'n_estimators': [1,100,200],\n        'seed': [0]}\nGS = GridSearchCV(estimator=model,param_grid=params,cv=3,n_jobs=-1, verbose=True, scoring='f1')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"GS.fit(X_train, Y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Best Parameters:',GS.best_params_,end='\\n\\n')\nprint('Best Score:',GS.best_score_)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from xgboost import XGBClassifier\n\nmodel = XGBClassifier(colsample_bytree= 1 , gamma = 0 , max_depth= 10, min_child_weight= 1, n_estimators=100, reg_alpha= 1, reg_lambda= 1, seed= 0)\nstart_time = timeit.default_timer()\nmodel.fit(X_train, Y_train)\nend_time = timeit.default_timer()\nelapsed_time = end_time - start_time\n\nprint(\"Elapsed time : \",elapsed_time)\n\n#Accuracy on training data\nx_train_prediction = model.predict(X_train)\ntraining_data_accuracy = accuracy_score(x_train_prediction , Y_train)\nprint('Accuracy on Training data : , ', training_data_accuracy)\n\n# accuracy on test data \nx_test_prediction = model.predict(X_test)\ntest_data_accuracy=accuracy_score(x_test_prediction,Y_test)\nprint('Accuracy score on Test data XGBost:' ,test_data_accuracy)\ngenerate_model_report(Y_test, x_test_prediction)\n\nconfusion_matrix(x_test_prediction,Y_test)\ncf_matrix=confusion_matrix(x_test_prediction,Y_test)\nprint(cf_matrix)\nsns.heatmap(cf_matrix, annot=True, cmap='Blues',fmt='g')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nrf = RandomForestClassifier(n_jobs=4,random_state=2018,criterion='entropy',n_estimators=100,verbose=False)\nstart_time = timeit.default_timer()\nrf.fit(X_train, Y_train)\n\nend_time = timeit.default_timer()\nelapsed_time = end_time - start_time\n\nprint(\"Elapsed time : \",elapsed_time)\n\nx_train_prediction = rf.predict(X_train)\ntraining_data_accuracy = accuracy_score(x_train_prediction , Y_train)\nprint('Accuracy on Training data : , ', training_data_accuracy)\n\n# accuracy on test data \nx_test_prediction = rf.predict(X_test)\ntest_data_accuracy=accuracy_score(x_test_prediction,Y_test)\nprint('Accuracy score on Test data RF :' ,test_data_accuracy)\n\ngenerate_model_report(Y_test, x_test_prediction)\n#print(confusion_matrix(x_test_prediction,Y_test))\nconfusion_matrix(x_test_prediction,Y_test)\ncf_matrix=confusion_matrix(x_test_prediction,Y_test)\nprint(cf_matrix)\nsns.heatmap(cf_matrix, annot=True, cmap='Blues',fmt='g')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Hyperparameter for ANN","metadata":{}},{"cell_type":"code","source":"from sklearn.neural_network import MLPClassifier\n#{'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (10, 30, 30), 'learning_rate': 'invscaling', 'max_iter': 10000, 'solver': 'adam'}\n\nMLPC = MLPClassifier()\nparams = {\n    'hidden_layer_sizes': [(10,30,10),(20,20,10),(20,40),(30,20,10)]\n    #'activation': ['tanh'],\n    #'solver': [ 'adam'],\n    #'alpha': [0.0001],\n    #'learning_rate': ['adaptive'],\n    #'max_iter':[10000,30000]\n}","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"GS = GridSearchCV(estimator=MLPC,param_grid=params,cv=3,n_jobs=-1, verbose=True, scoring='recall')\nGS.fit(X_train, Y_train)\nprint('Best Parameters:',GS.best_params_,end='\\n\\n')\nprint('Best Score:',GS.best_score_)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.neural_network import MLPClassifier\n\nMLPC = MLPClassifier(activation= 'tanh', alpha= 0.0001, hidden_layer_sizes=(12, 40, 30), learning_rate= 'adaptive', max_iter= 4000, solver= 'adam')\nstart_time = timeit.default_timer()\nMLPC.fit(X_train,Y_train)\nend_time = timeit.default_timer()\nelapsed_time = end_time - start_time\n\nprint(\"Elapsed time : \",elapsed_time)\n\n#Accuracy on training data\nx_train_prediction = MLPC.predict(X_train)\ntraining_data_accuracy = accuracy_score(x_train_prediction , Y_train)\nprint('Accuracy on Training data : , ', training_data_accuracy)\n\n# accuracy on test data \nx_test_prediction = MLPC.predict(X_test)\ntest_data_accuracy=accuracy_score(x_test_prediction,Y_test)\nprint('Accuracy score on Test data ANN :' ,test_data_accuracy)\n\ngenerate_model_report(Y_test, x_test_prediction)\n#print(confusion_matrix(x_test_prediction,Y_test))\nconfusion_matrix(x_test_prediction,Y_test)\ncf_matrix=confusion_matrix(x_test_prediction,Y_test)\nprint(cf_matrix)\nsns.heatmap(cf_matrix, annot=True, cmap='Blues',fmt='g')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Hyperparameter for KNN","metadata":{}},{"cell_type":"code","source":"n_neighbors=5, *, weights=\"uniform\", algorithm=\"auto\", leaf_size=30, p=2, metric=\"minkowski\"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier \nmodel = KNeighborsClassifier()\nparams = { 'n_neighbors':[5,10,15], 'weights':['uniform', 'distance'], 'algorithm':['auto', 'ball_tree', 'kd_tree', 'brute'], 'leaf_size':[20,30,50],'metric':'['minkowski']\n                }\nGS = GridSearchCV(estimator=model,param_grid=params,cv=3,n_jobs=-1, verbose=True, scoring='accuracy')\nGS.fit(X_train, Y_train)\nprint('Best Parameters:',GS.best_params_,end='\\n\\n')\nprint('Best Score:',GS.best_score_)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier \nknn = KNeighborsClassifier(n_neighbors= 9,metric='manhattan',weights='uniform')\nstart_time =timeit.default_timer()\nknn.fit(X_train,Y_train)\n\nend_time = timeit.default_timer()\nelapsed_time = end_time - start_time\n\nprint(\"Elapsed time : \",elapsed_time)\n#Accuracy on training data\nx_train_prediction = knn.predict(X_train)\ntraining_data_accuracy = accuracy_score(x_train_prediction , Y_train)\nprint('Accuracy on Training data : , ', training_data_accuracy)\n# accuracy on test data \nx_test_prediction  = knn.predict(X_test)\ntest_data_accuracy = accuracy_score(x_test_prediction,Y_test)\nprint('Accuracy score on Test data KNN :' ,test_data_accuracy)\nY_Test_Pred = knn.predict(X_test)\ngenerate_model_report(Y_test, Y_Test_Pred)\nconfusion_matrix(x_test_prediction,Y_test)\ncf_matrix=confusion_matrix(x_test_prediction,Y_test)\nprint(cf_matrix)\nsns.heatmap(cf_matrix, annot=True, cmap='Blues',fmt='g')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"logModel = LogisticRegression()\nstart_time = perf_counter()\nlogModel.fit(X_train, Y_train)\nend_time = perf_counter()\nelapsed_time = end_time - start_time\n\nprint(\"Elapsed time : \",elapsed_time)\n\n#Accuracy on training data\nx_train_prediction = logModel.predict(X_train)\ntraining_data_accuracy = accuracy_score(x_train_prediction , Y_train)\nprint('Accuracy on Training data : , ', training_data_accuracy)\n\n# accuracy on test data \nx_test_prediction = logModel.predict(X_test)\ntest_data_accuracy=accuracy_score(x_test_prediction,Y_test)\nprint('Accuracy score on Test data :' ,test_data_accuracy)\ngenerate_model_report(Y_test, x_test_prediction)\nprint(confusion_matrix(x_test_prediction,Y_test))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Catboost Hyperparameter","metadata":{}},{"cell_type":"code","source":"from catboost import CatBoostClassifier\ncb_clf = CatBoostClassifier()\n\nparams = {\n    'learning_rate': [0.03, 0.06],\n    'depth':[3, 9],\n   # 'l2_leaf_reg': [2, 3, 4],\n   # 'boosting_type': ['Ordered', 'Plain']\n}\n\nGS = GridSearchCV(estimator=cb_clf,param_grid=params,cv=3,n_jobs=-1, verbose=True, scoring='accuracy')\nGS.fit(X_train, Y_train)\nprint('Best Parameters:',GS.best_params_,end='\\n\\n')\nprint('Best Score:',GS.best_score_)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''learning_rate': [0.03, 0.06],\n    'depth':[3, 6, 9],\n    'l2_leaf_reg': [2, 3, 4],\n    'boosting_type': ['Ordered', 'Plain']'''\n\nfrom catboost import CatBoostClassifier\n\ncb_clf = CatBoostClassifier(learning_rate=0.03,depth=9)\ncb_clf.fit(X_train, Y_train)\n#y_train_pred = cb_clf.predict(X_train)\n#y_test_pred = cb_clf.predict(X_test)\n\n#Accuracy on training data\nx_train_prediction = model.predict(X_train)\ntraining_data_accuracy = accuracy_score(x_train_prediction , Y_train)\nprint('Accuracy on Training data : , ', training_data_accuracy)\n\n# accuracy on test data \nx_test_prediction = model.predict(X_test)\ntest_data_accuracy=accuracy_score(x_test_prediction,Y_test)\nprint('Accuracy score on Test data :' ,test_data_accuracy)\ngenerate_model_report(Y_test, x_test_prediction)\nconfusion_matrix(x_test_prediction,Y_test)\ncf_matrix=confusion_matrix(x_test_prediction,Y_test)\nprint(cf_matrix)\nsns.heatmap(cf_matrix, annot=True, cmap='Blues')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.naive_bayes import BernoulliNB\nmodel = BernoulliNB(binarize=0.0)\nstart_time = timeit.default_timer()\nmodel.fit(X_train,Y_train)\n\nend_time = timeit.default_timer()\nelapsed_time = end_time - start_time\n\nprint(\"Elapsed time : \",elapsed_time)\n\n#Accuracy on training data\nx_train_prediction = model.predict(X_train)\ntraining_data_accuracy = accuracy_score(x_train_prediction , Y_train)\nprint('Accuracy on Training data : , ', training_data_accuracy)\n# accuracy on test data \nx_test_prediction = model.predict(X_test)\ntest_data_accuracy=accuracy_score(x_test_prediction,Y_test)\nprint('Accuracy score on Test data :' ,test_data_accuracy)\ngenerate_model_report(Y_test, x_test_prediction)\nprint(confusion_matrix(x_test_prediction,Y_test))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# ROC-AUC curve","metadata":{}},{"cell_type":"code","source":"    y_pred_proba_dt = classify_.predict_proba(X_test)[:, 1]\n    fpr_dt, tpr_dt, thresholds = roc_curve(Y_test,  y_pred_proba_dt)\n    auc_dt = roc_auc_score(Y_test, y_pred_proba_dt)\n    \n    y_pred_proba_xb = model.predict_proba(X_test)[:, 1]\n    fpr_xb, tpr_xb, thresholds = roc_curve(Y_test,  y_pred_proba_xb)\n    auc_xb = roc_auc_score(Y_test, y_pred_proba_xb)\n    \n    y_pred_proba_rf = rf.predict_proba(X_test)[:, 1]\n    fpr_rf, tpr_rf, thresholds = roc_curve(Y_test,  y_pred_proba_rf)\n    auc_rf = roc_auc_score(Y_test, y_pred_proba_rf)\n    \n    y_pred_proba_ann = MLPC.predict_proba(X_test)[:, 1]\n    fpr_ann, tpr_ann, thresholds = roc_curve(Y_test,  y_pred_proba_ann)\n    auc_ann = roc_auc_score(Y_test, y_pred_proba_ann)\n    \n    y_pred_proba_knn = knn.predict_proba(X_test)[:, 1]\n    fpr_knn, tpr_knn, thresholds = roc_curve(Y_test,  y_pred_proba_knn)\n    auc_knn = roc_auc_score(Y_test, y_pred_proba_knn)\n    \n   # y_pred_proba_cb = cb_clf.predict_proba(X_test)[:, 1]\n    #fpr_cb, tpr_cb, thresholds = roc_curve(Y_test,  y_pred_proba_cb)\n    #auc_cb = roc_auc_score(Y_test, y_pred_proba_cb)\n    \n    plt.figure(figsize=(5, 5), dpi=100)\n    plt.xlabel('False Positive Rate')\n    plt.ylabel('True Positive Rate')\n    \n    plt.plot(fpr_dt,tpr_dt,linestyle='solid',label=\"DTC =\"+str(auc_dt))\n    plt.plot(fpr_xb,tpr_xb,linestyle='dotted',label=\"XGBC =\"+str(auc_xb))\n    plt.plot(fpr_rf,tpr_rf,linestyle='dashed',label=\"RFC =\"+str(auc_rf))\n    plt.plot(fpr_ann,tpr_ann,linestyle='-.',label=\"ANN =\"+str(auc_ann))\n    plt.plot(fpr_knn,tpr_knn,linestyle='dashdot',label=\"KNN =\"+str(auc_knn))\n    #plt.plot(fpr_cb,tpr_cb,linestyle=':',label=\"CatBoost =\"+str(auc_cb))\n    plt.legend(loc=4)\n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Precision Recall Curve","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import precision_recall_curve\nfrom sklearn import metrics\n#print('Logistic PR-AUC: %.3f'% auc_score)\ny_test_prob_rf=rf.predict_proba(X_test)[:,1]\nprecision_rf, recall_rf,_ =precision_recall_curve(Y_test, y_test_prob_rf)\nauc_score_rf=metrics.auc(recall_rf, precision_rf)\ny_test_prob_xb=model.predict_proba(X_test)[:,1]\nprecision_xb, recall_xb,_ =precision_recall_curve(Y_test, y_test_prob_xb)\nauc_score_xb=metrics.auc(recall_xb, precision_xb)\ny_test_prob_dt=classify_.predict_proba(X_test)[:,1]\nprecision_dt, recall_dt,_ =precision_recall_curve(Y_test, y_test_prob_dt)\nauc_score_dt=metrics.auc(recall_dt, precision_dt)\ny_test_prob_knn=knn.predict_proba(X_test)[:,1]\nprecision_knn, recall_knn,_ =precision_recall_curve(Y_test, y_test_prob_knn)\nauc_score_knn=metrics.auc(recall_knn, precision_knn)\ny_test_prob_ann=MLPC.predict_proba(X_test)[:,1]\nprecision_ann, recall_ann,_ =precision_recall_curve(Y_test, y_test_prob_ann)\nauc_score_ann=metrics.auc(recall_ann, precision_ann)\nplt.figure(figsize=(5,5))\nplt.plot(recall, precision, marker='',label=\"RFC=\"+str(auc_score_rf))\nplt.plot(recall, precision, marker='',label=\"KNN=\"+str(auc_score_knn))\nplt.plot(recall, precision, marker='',label=\"ANN=\"+str(auc_score_ann))\nplt.plot(recall, precision, marker='',label=\"DTC=\"+str(auc_score_dt))\nplt.plot(recall, precision, marker='',label=\"XGBC=\"+str(auc_score_xb))\nplt.xlabel(\"Recall\")\nplt.ylabel(\"Precision\")\nplt.title(\"Recall-Precision Curve on RFC\")\nplt.legend()\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}